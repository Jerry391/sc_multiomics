{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e28da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cjerry/anaconda3/lib/python3.11/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n",
      "  self.seed = seed\n",
      "/Users/cjerry/anaconda3/lib/python3.11/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n",
      "  self.dl_pin_memory_gpu_training = (\n",
      "/Users/cjerry/anaconda3/lib/python3.11/site-packages/rpy2/robjects/pandas2ri.py:368: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/Users/cjerry/anaconda3/lib/python3.11/site-packages/rpy2/robjects/numpy2ri.py:252: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/var/folders/w_/jfhkzbcx6311zqlbnq7j9mm80000gn/T/ipykernel_51953/3275284299.py:24: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  anndata2ri.activate()\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import muon as mu\n",
    "import anndata2ri\n",
    "import logging\n",
    "import scvi\n",
    "import os\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scib\n",
    "import rpy2.rinterface_lib.callbacks\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rpy2.robjects import r\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR)\n",
    "\n",
    "pandas2ri.activate()\n",
    "anndata2ri.activate()\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70fdd74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Please select a CRAN mirror for use in this session ---\n",
      "Secure CRAN mirrors \n",
      "\n",
      " 1: 0-Cloud [https]\n",
      " 2: Australia (Canberra) [https]\n",
      " 3: Australia (Melbourne 1) [https]\n",
      " 4: Australia (Melbourne 2) [https]\n",
      " 5: Australia (Perth) [https]\n",
      " 6: Austria [https]\n",
      " 7: Belgium (Brussels) [https]\n",
      " 8: Brazil (PR) [https]\n",
      " 9: Brazil (RJ) [https]\n",
      "10: Brazil (SP 1) [https]\n",
      "11: Brazil (SP 2) [https]\n",
      "12: Bulgaria [https]\n",
      "13: Canada (MB) [https]\n",
      "14: Canada (ON 3) [https]\n",
      "15: Chile (Santiago) [https]\n",
      "16: China (Beijing 2) [https]\n",
      "17: China (Beijing 3) [https]\n",
      "18: China (Hefei) [https]\n",
      "19: China (Hong Kong) [https]\n",
      "20: China (Guangzhou) [https]\n",
      "21: China (Jinan) [https]\n",
      "22: China (Lanzhou) [https]\n",
      "23: China (Nanjing) [https]\n",
      "24: China (Shanghai 2) [https]\n",
      "25: China (Shenzhen) [https]\n",
      "26: Colombia (Cali) [https]\n",
      "27: Costa Rica [https]\n",
      "28: Czech Republic [https]\n",
      "29: Denmark [https]\n",
      "30: East Asia [https]\n",
      "31: Ecuador (Cuenca) [https]\n",
      "32: France (Lyon 1) [https]\n",
      "33: France (Lyon 2) [https]\n",
      "34: France (Marseille) [https]\n",
      "35: France (Paris 1) [https]\n",
      "36: Germany (Erlangen) [https]\n",
      "37: Germany (Leipzig) [https]\n",
      "38: Germany (Göttingen) [https]\n",
      "39: Germany (Münster) [https]\n",
      "40: Germany (Regensburg) [https]\n",
      "41: Greece [https]\n",
      "42: Hungary [https]\n",
      "43: Iceland [https]\n",
      "44: India [https]\n",
      "45: Indonesia (Banda Aceh) [https]\n",
      "46: Iran (Mashhad) [https]\n",
      "47: Italy (Milano) [https]\n",
      "48: Italy (Padua) [https]\n",
      "49: Japan (Tokyo) [https]\n",
      "50: Japan (Yonezawa) [https]\n",
      "51: Korea (Gyeongsan-si) [https]\n",
      "52: Malaysia [https]\n",
      "53: Mexico (Mexico City) [https]\n",
      "54: Mexico (Texcoco) [https]\n",
      "55: Morocco [https]\n",
      "56: Netherlands (Dronten) [https]\n",
      "57: New Zealand [https]\n",
      "58: Norway [https]\n",
      "59: South Africa (Johannesburg) [https]\n",
      "60: Spain (A Coruña) [https]\n",
      "61: Spain (Madrid) [https]\n",
      "62: Sweden (Umeå) [https]\n",
      "63: Switzerland (Zurich 1) [https]\n",
      "64: Taiwan (Taipei) [https]\n",
      "65: Turkey (Denizli) [https]\n",
      "66: Turkey (Istanbul) [https]\n",
      "67: Turkey (Mersin) [https]\n",
      "68: UK (Bristol) [https]\n",
      "69: UK (London 1) [https]\n",
      "70: USA (IA) [https]\n",
      "71: USA (MI) [https]\n",
      "72: USA (MO) [https]\n",
      "73: USA (OH) [https]\n",
      "74: USA (OR) [https]\n",
      "75: USA (TN) [https]\n",
      "76: United Arab Emirates [https]\n",
      "77: Uruguay [https]\n",
      "78: (other mirrors)\n",
      "\n",
      "Selection: 74\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/w_/jfhkzbcx6311zqlbnq7j9mm80000gn/T//RtmpXSMkpe/downloaded_packages\n",
      "\n",
      "    WARNING: The R package \"reticulate\" only fixed recently\n",
      "    an issue that caused a segfault when used with rpy2:\n",
      "    https://github.com/rstudio/reticulate/pull/1188\n",
      "    Make sure that you use a version of that package that includes\n",
      "    the fix.\n",
      "    "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Warning: failed to download mirrors file (cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv'); using local file '/Library/Frameworks/R.framework/Resources/doc/CRAN_mirrors.csv'\n",
       "trying URL 'https://ftp.osuosl.org/pub/cran/bin/macosx/big-sur-arm64/contrib/4.3/Seurat_4.4.0.tgz'\n",
       "Content type 'application/x-gzip' length 3762575 bytes (3.6 MB)\n",
       "==================================================\n",
       "downloaded 3.6 MB\n",
       "\n",
       "In addition: Warning messages:\n",
       "1: In download.file(url, destfile = f, quiet = TRUE) :\n",
       "  URL 'https://cran.r-project.org/CRAN_mirrors.csv': status was 'Couldn't resolve host name'\n",
       "2: In doTryCatch(return(expr), name, parentenv, handler) :\n",
       "  unable to load shared object '/Library/Frameworks/R.framework/Resources/modules//R_X11.so':\n",
       "  dlopen(/Library/Frameworks/R.framework/Resources/modules//R_X11.so, 0x0006): Library not loaded: /opt/X11/lib/libSM.6.dylib\n",
       "  Referenced from: <B3716E5A-BF4D-3CA3-B8EB-89643DB72A04> /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/modules/R_X11.so\n",
       "  Reason: tried: '/opt/X11/lib/libSM.6.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/X11/lib/libSM.6.dylib' (no such file), '/opt/X11/lib/libSM.6.dylib' (no such file), '/usr/local/lib/libSM.6.dylib' (no such file), '/usr/lib/libSM.6.dylib' (no such file, not in dyld cache)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "install.packages('Seurat')\n",
    "suppressPackageStartupMessages({\n",
    "    library(Seurat)\n",
    "})\n",
    "set.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eddc2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>MuData object with n_obs × n_vars = 10970 × 148344\n",
       "  var:\t&#x27;gene_ids&#x27;, &#x27;feature_types&#x27;\n",
       "  2 modalities\n",
       "    rna:\t10970 x 36601\n",
       "      var:\t&#x27;gene_ids&#x27;, &#x27;feature_types&#x27;\n",
       "    atac:\t10970 x 111743\n",
       "      var:\t&#x27;gene_ids&#x27;, &#x27;feature_types&#x27;</pre>"
      ],
      "text/plain": [
       "MuData object with n_obs × n_vars = 10970 × 148344\n",
       "  var:\t'gene_ids', 'feature_types'\n",
       "  2 modalities\n",
       "    rna:\t10970 x 36601\n",
       "      var:\t'gene_ids', 'feature_types'\n",
       "    atac:\t10970 x 111743\n",
       "      var:\t'gene_ids', 'feature_types'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adt = sc.read(\n",
    "#     \"/lustre/groups/ml01/workspace/anastasia.litinetskaya/data/neurips-cite/adt_pp.h5ad\"\n",
    "# )\n",
    "adt = mu.read_10x_mtx(\n",
    "    'filtered_feature_bc_matrix/',  # the directory with the `.mtx` file\n",
    "    var_names='gene_symbols',                # use gene symbols for the variable names (variables-axis index)\n",
    "    cache=True)                              # write a cache file for faster subsequent reading\n",
    "adt.var_names_make_unique()  # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`\n",
    "adt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acfdea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"# cells, # genes before filtering:\", adt.shape)\n",
    "\n",
    "# sc.pp.filter_genes(adt, min_counts=3)\n",
    "# sc.pp.filter_cells(adt, min_counts=3)\n",
    "\n",
    "# print(\"# cells, # genes after filtering:\", adt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c63b2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = len(adt[\"rna\"].var_names)\n",
    "n_regions = len(adt[\"atac\"].var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc6ac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 10970 × 36601\n",
       "    obs: 'modality'\n",
       "    var: 'gene_ids', 'feature_types'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_paired = sc.read_10x_mtx(\n",
    "    'filtered_feature_bc_matrix/',  # the directory with the `.mtx` file\n",
    "    var_names='gene_symbols',                # use gene symbols for the variable names (variables-axis index)\n",
    "    cache=True) \n",
    "adata_paired.obs[\"modality\"] = \"paired\"\n",
    "adata_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e7d2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_mvi = scvi.data.organize_multiome_anndatas(adata_paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e375a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.model.MULTIVI.setup_anndata(\n",
    "    adata_mvi,\n",
    "    batch_key=\"modality\",\n",
    "#     categorical_covariate_keys=[\"batch\"],\n",
    "#     layer=\"counts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beae9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvi = scvi.model.MULTIVI(\n",
    "    adata_mvi,\n",
    "    n_genes=n_genes,\n",
    "    n_regions=n_regions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb983a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "num_cores = os.cpu_count()\n",
    "print(num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a5c4de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of CPU cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adfbe63e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "You requested gpu: [0, 1, 2]\n But your machine only has: [0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# mvi.train()\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mvi\u001b[38;5;241m.\u001b[39mtrain(devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scvi/model/_multivi.py:339\u001b[0m, in \u001b[0;36mMULTIVI.train\u001b[0;34m(self, max_epochs, lr, use_gpu, accelerator, devices, train_size, validation_size, shuffle_set_split, batch_size, weight_decay, eps, early_stopping, save_best, check_val_every_n_epoch, n_steps_kl_warmup, n_epochs_kl_warmup, adversarial_mixing, plan_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m data_splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_splitter_cls(\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madata_manager,\n\u001b[1;32m    333\u001b[0m     train_size\u001b[38;5;241m=\u001b[39mtrain_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    337\u001b[0m )\n\u001b[1;32m    338\u001b[0m training_plan \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_plan_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplan_kwargs)\n\u001b[0;32m--> 339\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_runner_cls(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     training_plan\u001b[38;5;241m=\u001b[39mtraining_plan,\n\u001b[1;32m    342\u001b[0m     data_splitter\u001b[38;5;241m=\u001b[39mdata_splitter,\n\u001b[1;32m    343\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[1;32m    344\u001b[0m     use_gpu\u001b[38;5;241m=\u001b[39muse_gpu,\n\u001b[1;32m    345\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39maccelerator,\n\u001b[1;32m    346\u001b[0m     devices\u001b[38;5;241m=\u001b[39mdevices,\n\u001b[1;32m    347\u001b[0m     early_stopping\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[1;32m    348\u001b[0m     check_val_every_n_epoch\u001b[38;5;241m=\u001b[39mcheck_val_every_n_epoch,\n\u001b[1;32m    349\u001b[0m     early_stopping_monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreconstruction_loss_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    350\u001b[0m     early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    352\u001b[0m )\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m runner()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scvi/train/_trainrunner.py:76\u001b[0m, in \u001b[0;36mTrainRunner.__init__\u001b[0;34m(self, model, training_plan, data_splitter, max_epochs, use_gpu, accelerator, devices, **trainer_kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_splitter \u001b[38;5;241m=\u001b[39m data_splitter\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m---> 76\u001b[0m accelerator, lightning_devices, device \u001b[38;5;241m=\u001b[39m parse_device_args(\n\u001b[1;32m     77\u001b[0m     use_gpu\u001b[38;5;241m=\u001b[39muse_gpu,\n\u001b[1;32m     78\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39maccelerator,\n\u001b[1;32m     79\u001b[0m     devices\u001b[38;5;241m=\u001b[39mdevices,\n\u001b[1;32m     80\u001b[0m     return_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;241m=\u001b[39m accelerator\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_devices \u001b[38;5;241m=\u001b[39m lightning_devices\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scvi/model/_utils.py:103\u001b[0m, in \u001b[0;36mparse_device_args\u001b[0;34m(use_gpu, accelerator, devices, return_device, validate_single_device)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _validate_single_device \u001b[38;5;129;01mand\u001b[39;00m (cond1 \u001b[38;5;129;01mor\u001b[39;00m cond2 \u001b[38;5;129;01mor\u001b[39;00m cond3):\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly a single device can be specified for `device`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 103\u001b[0m connector \u001b[38;5;241m=\u001b[39m _AcceleratorConnector(accelerator\u001b[38;5;241m=\u001b[39maccelerator, devices\u001b[38;5;241m=\u001b[39mdevices)\n\u001b[1;32m    104\u001b[0m _accelerator \u001b[38;5;241m=\u001b[39m connector\u001b[38;5;241m.\u001b[39m_accelerator_flag\n\u001b[1;32m    105\u001b[0m _devices \u001b[38;5;241m=\u001b[39m connector\u001b[38;5;241m.\u001b[39m_devices_flag\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:157\u001b[0m, in \u001b[0;36m_AcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerator_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_choose_gpu_accelerator_backend()\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_device_config_and_set_final_flags(devices\u001b[38;5;241m=\u001b[39mdevices, num_nodes\u001b[38;5;241m=\u001b[39mnum_nodes)\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_parallel_devices_and_init_accelerator()\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# 3. Instantiate ClusterEnvironment\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_environment: ClusterEnvironment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_choose_and_init_cluster_environment()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:390\u001b[0m, in \u001b[0;36m_AcceleratorConnector._set_parallel_devices_and_init_accelerator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccelerator_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` can not run on your system\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m since the accelerator is not available. The following accelerator(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is available and can be passed into `accelerator` argument of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `Trainer`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavailable_accelerator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    387\u001b[0m     )\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_devices_flag_if_auto_passed()\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_devices_flag \u001b[38;5;241m=\u001b[39m accelerator_cls\u001b[38;5;241m.\u001b[39mparse_devices(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_devices_flag)\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parallel_devices:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parallel_devices \u001b[38;5;241m=\u001b[39m accelerator_cls\u001b[38;5;241m.\u001b[39mget_parallel_devices(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_devices_flag)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/accelerators/mps.py:53\u001b[0m, in \u001b[0;36mMPSAccelerator.parse_devices\u001b[0;34m(devices)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_devices\u001b[39m(devices: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mint\u001b[39m]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[List[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Accelerator device parsing logic.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_gpu_ids(devices, include_mps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/fabric/utilities/device_parser.py:102\u001b[0m, in \u001b[0;36m_parse_gpu_ids\u001b[0;34m(gpus, include_cuda, include_mps)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Check that GPUs are unique. Duplicate GPUs are not supported by the backend.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m _check_unique(gpus)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _sanitize_gpu_ids(gpus, include_cuda\u001b[38;5;241m=\u001b[39minclude_cuda, include_mps\u001b[38;5;241m=\u001b[39minclude_mps)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/fabric/utilities/device_parser.py:135\u001b[0m, in \u001b[0;36m_sanitize_gpu_ids\u001b[0;34m(gpus, include_cuda, include_mps)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gpu \u001b[38;5;129;01min\u001b[39;00m gpus:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gpu \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_available_gpus:\n\u001b[0;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou requested gpu: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m But your machine only has: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_available_gpus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         )\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gpus\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: You requested gpu: [0, 1, 2]\n But your machine only has: [0]"
     ]
    }
   ],
   "source": [
    "# mvi.train()\n",
    "mvi.train(devices=num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37888277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f528d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d80063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94233b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba788979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc1b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
